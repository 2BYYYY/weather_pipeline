services:
  db:
    container_name: postgres_container
    image: postgres:15.15
    ports:
      - 5000:5432
    environment:
      POSTGRES_DB: db
      POSTGRES_USER: db_user
      POSTGRES_PASSWORD: db_password
    volumes:
      #PG filesystem https://hub.docker.com/_/postgres
      #Local data <--> Docker postgres data
      - ./postgres/data:/var/lib/postgresql/data
      - ./postgres/airflow_init.sql:/docker-entrypoint-initdb.d/airflow_init.sql
    networks:
     - my-network
    healthcheck:
        #Complete the config not only -U db_user to avoid the "no user spam"
        test: ["CMD-SHELL", "pg_isready -U db_user -d db"]
        interval: 5s
        timeout: 5s
        retries: 5
    
  af:
    container_name: airflow_container
    image: apache/airflow:3.1.3
    ports:
      - 8000:8080
    environment:
      #Connect to metadata database via the service db (postgres)
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@db:5432/airflow_db
    env_file:
    - ./airflow/.env
    volumes:
      #AF filesystem https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html
      #Local data <--> Docker airflow data
     - ./airflow/dags:/opt/airflow/dags
     - ./airflow/plugins:/opt/airflow/plugins
    #Controls startup order (db first then af) 
    depends_on:
      db:
        condition: service_healthy
    networks:
     - my-network
    command: >
      bash -c "airflow db migrate && airflow standalone"

  dbt:
    container_name: dbt_container
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.latest
    volumes:
      #PG filesystem https://hub.docker.com/_/postgres
      - ./dbt/my_project:/usr/app
      - ./dbt:/root/.dbt
    working_dir: /usr/app
    environment:
      DBT_PROFILES_DIR: "/root/.dbt"
    depends_on:
      db:
        condition: service_healthy
    networks:
      - my-network
    command: run
    
networks:
  my-network:
    driver: bridge
